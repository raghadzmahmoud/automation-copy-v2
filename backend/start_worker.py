#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ğŸ”„ Sequential Task Scheduler
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ÙŠØ´ØºÙ„ Ø§Ù„Ù€ jobs Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨ Ø¨Ø¯Ù„ parallel
Ø£ÙØ¶Ù„ Ù„Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø­Ø¯ÙˆØ¯Ø© ÙˆÙŠØ¶Ù…Ù† Ø§Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„ØµØ­ÙŠØ­

Flow:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Loop ÙƒÙ„ 2 Ø¯Ù‚ÙŠÙ‚Ø©:                                           â”‚
â”‚                                                             â”‚
â”‚  1. ğŸ“¥ Scraping (ÙƒÙ„ cycle)                                  â”‚
â”‚  2. ğŸ”„ Processing: cluster â†’ report â†’ social (ÙƒÙ„ cycle)     â”‚
â”‚  3. ğŸ¨ Media: image â†’ audio (ÙƒÙ„ cycle Ø«Ø§Ù†ÙŠ)                 â”‚
â”‚  4. ğŸ“¤ Publishing: social_img â†’ reel â†’ publish (ÙƒÙ„ 3 cycles)â”‚
â”‚  5. ğŸ“» Broadcast (ÙƒÙ„ 3 cycles)                              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import time
import signal
import logging
import traceback
from datetime import datetime, timezone
from typing import Dict, Optional

import certifi
import psycopg2

# Set SSL certificate
os.environ["SSL_CERT_FILE"] = certifi.where()

# Add path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from settings import DB_CONFIG

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Logging Setup
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

log_dir = 'logs'
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(f'{log_dir}/worker.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Job Imports (Lazy Loading)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def import_jobs():
    """Import all job functions"""
    global scrape_news, cluster_news, generate_reports
    global generate_social_media_content, generate_images, generate_audio
    global generate_social_media_images, generate_reels, publish_to_social_media
    global generate_all_broadcasts
    
    from app.jobs.scraper_job import scrape_news
    from app.jobs.clustering_job import cluster_news
    from app.jobs.reports_job import generate_reports
    from app.jobs.social_media_job import generate_social_media_content
    from app.jobs.image_generation_job import generate_images
    from app.jobs.audio_generation_job import generate_audio
    from app.jobs.social_media_image_job import generate_social_media_images
    from app.jobs.reel_generation_job import generate_reels
    from app.jobs.publishers_job import publish_to_social_media
    from app.jobs.broadcast_job import generate_all_broadcasts
    
    logger.info("âœ… All jobs imported successfully")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Configuration
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ø§Ù„ÙØªØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ø¯ÙˆØ±Ø§Øª (Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ)
BASE_CYCLE_INTERVAL = int(os.getenv('CYCLE_INTERVAL', 120))  # 2 Ø¯Ù‚ÙŠÙ‚Ø© default

# ÙƒÙ„ ÙƒÙ… Ø¯ÙˆØ±Ø© ÙŠØ´ØªØºÙ„ ÙƒÙ„ group
CYCLE_CONFIG = {
    'scraping': 1,           # ÙƒÙ„ Ø¯ÙˆØ±Ø© (ÙƒÙ„ 2 Ø¯Ù‚)
    'processing': 1,         # ÙƒÙ„ Ø¯ÙˆØ±Ø© (ÙƒÙ„ 2 Ø¯Ù‚)
    'media_generation': 2,   # ÙƒÙ„ Ø¯ÙˆØ±ØªÙŠÙ† (ÙƒÙ„ 4 Ø¯Ù‚)
    'publishing': 3,         # ÙƒÙ„ 3 Ø¯ÙˆØ±Ø§Øª (ÙƒÙ„ 6 Ø¯Ù‚)
    'broadcast': 3,          # ÙƒÙ„ 3 Ø¯ÙˆØ±Ø§Øª (ÙƒÙ„ 6 Ø¯Ù‚)
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Job Execution
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_job(name: str, func, skip_on_error: bool = True) -> Dict:
    """
    ØªØ´ØºÙŠÙ„ job ÙˆØ§Ø­Ø¯ Ù…Ø¹ logging
    
    Args:
        name: Ø§Ø³Ù… Ø§Ù„Ù€ job Ù„Ù„Ù€ logging
        func: Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ù„ÙŠ ØªØ´ØºÙ„Ù‡Ø§
        skip_on_error: ØªÙƒÙ…Ù„ Ø­ØªÙ‰ Ù„Ùˆ ÙØ´Ù„ØŸ
    
    Returns:
        dict: Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
    """
    logger.info(f"â–¶ï¸  Starting: {name}")
    start_time = datetime.now()
    
    try:
        result = func()
        duration = (datetime.now() - start_time).total_seconds()
        
        if result.get('skipped'):
            logger.info(f"â­ï¸  {name}: Skipped ({result.get('reason', 'no reason')})")
        elif result.get('error'):
            logger.error(f"âŒ {name}: Error - {result.get('error')}")
        else:
            logger.info(f"âœ… {name}: Completed in {duration:.1f}s")
        
        return {
            'success': not result.get('error'),
            'skipped': result.get('skipped', False),
            'duration': duration,
            'result': result
        }
        
    except Exception as e:
        duration = (datetime.now() - start_time).total_seconds()
        logger.error(f"âŒ {name}: Exception - {e}")
        
        if not skip_on_error:
            raise
        
        return {
            'success': False,
            'skipped': False,
            'duration': duration,
            'error': str(e)
        }


def run_group(group_name: str, jobs: list) -> Dict:
    """
    ØªØ´ØºÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© jobs Ø¨Ø§Ù„ØªØ±ØªÙŠØ¨
    
    Args:
        group_name: Ø§Ø³Ù… Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø©
        jobs: Ù‚Ø§Ø¦Ù…Ø© (name, func) Ù„Ù„Ù€ jobs
    
    Returns:
        dict: Ù†ØªØ§Ø¦Ø¬ ÙƒÙ„ Ø§Ù„Ù€ jobs
    """
    logger.info(f"\n{'â”€'*60}")
    logger.info(f"ğŸ”· GROUP: {group_name}")
    logger.info(f"{'â”€'*60}")
    
    group_start = datetime.now()
    results = {}
    
    for job_name, job_func in jobs:
        results[job_name] = run_job(job_name, job_func)
        
        # ÙØªØ±Ø© Ø±Ø§Ø­Ø© Ù‚ØµÙŠØ±Ø© Ø¨ÙŠÙ† Ø§Ù„Ù€ jobs
        time.sleep(2)
    
    group_duration = (datetime.now() - group_start).total_seconds()
    logger.info(f"ğŸ”· GROUP {group_name} completed in {group_duration:.1f}s")
    
    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main Cycle
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_cycle(cycle_number: int) -> Dict:
    """
    ØªØ´ØºÙŠÙ„ Ø¯ÙˆØ±Ø© ÙƒØ§Ù…Ù„Ø©
    
    Args:
        cycle_number: Ø±Ù‚Ù… Ø§Ù„Ø¯ÙˆØ±Ø© (ÙŠØ¨Ø¯Ø£ Ù…Ù† 1)
    
    Returns:
        dict: Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¯ÙˆØ±Ø©
    """
    cycle_start = datetime.now()
    
    logger.info("\n" + "â•"*70)
    logger.info(f"ğŸ”„ CYCLE #{cycle_number} started at {cycle_start.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("â•"*70)
    
    results = {}
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Group 1: Data Ingestion (Scraping)
    # ÙŠØ´ØªØºÙ„ ÙƒÙ„ Ø¯ÙˆØ±Ø©
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if cycle_number % CYCLE_CONFIG['scraping'] == 0:
        results['scraping'] = run_group('DATA INGESTION', [
            ('scraping', scrape_news),
        ])
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Group 2: Processing (Cluster â†’ Report â†’ Social Text)
    # ÙŠØ´ØªØºÙ„ ÙƒÙ„ Ø¯ÙˆØ±Ø©
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if cycle_number % CYCLE_CONFIG['processing'] == 0:
        results['processing'] = run_group('PROCESSING', [
            ('clustering', cluster_news),
            ('reports', generate_reports),
            ('social_media_text', generate_social_media_content),
        ])
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Group 3: Media Generation (Image + Audio)
    # ÙŠØ´ØªØºÙ„ ÙƒÙ„ Ø¯ÙˆØ±ØªÙŠÙ†
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if cycle_number % CYCLE_CONFIG['media_generation'] == 0:
        results['media'] = run_group('MEDIA GENERATION', [
            ('images', generate_images),
            ('audio', generate_audio),
        ])
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Group 4: Publishing (Social Image â†’ Reel â†’ Publish)
    # ÙŠØ´ØªØºÙ„ ÙƒÙ„ 3 Ø¯ÙˆØ±Ø§Øª
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if cycle_number % CYCLE_CONFIG['publishing'] == 0:
        results['publishing'] = run_group('PUBLISHING', [
            ('social_media_images', generate_social_media_images),
            ('reels', generate_reels),
            ('publishers', publish_to_social_media),
        ])
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Group 5: Broadcast (Bulletin + Digest)
    # ÙŠØ´ØªØºÙ„ ÙƒÙ„ 3 Ø¯ÙˆØ±Ø§Øª
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if cycle_number % CYCLE_CONFIG['broadcast'] == 0:
        results['broadcast'] = run_group('BROADCAST', [
            ('broadcast', generate_all_broadcasts),
        ])
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Summary
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cycle_duration = (datetime.now() - cycle_start).total_seconds()
    
    logger.info("\n" + "â•"*70)
    logger.info(f"ğŸ“Š CYCLE #{cycle_number} Summary")
    logger.info("â•"*70)
    logger.info(f"Duration: {cycle_duration:.1f}s ({cycle_duration/60:.1f} min)")
    
    for group_name, group_results in results.items():
        logger.info(f"\n  {group_name}:")
        for job_name, job_result in group_results.items():
            if job_result.get('skipped'):
                status = "â­ï¸"
            elif job_result.get('success'):
                status = "âœ…"
            else:
                status = "âŒ"
            logger.info(f"    {status} {job_name}: {job_result.get('duration', 0):.1f}s")
    
    logger.info("â•"*70 + "\n")
    
    return {
        'cycle': cycle_number,
        'duration': cycle_duration,
        'results': results
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main Loop
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Global flag for graceful shutdown
running = True


def signal_handler(signum, frame):
    """Handle shutdown signals"""
    global running
    logger.info("\nâš ï¸  Shutdown signal received, finishing current cycle...")
    running = False


def main():
    """Main entry point"""
    global running
    
    logger.info("â•"*70)
    logger.info("ğŸš€ Sequential Task Scheduler Starting")
    logger.info("â•"*70)
    logger.info(f"Environment: {os.getenv('ENVIRONMENT', 'development')}")
    
    # Check FFmpeg availability
    try:
        from app.utils.audio_converter import AudioConverter
        audio_converter = AudioConverter()
        
        if audio_converter.is_ffmpeg_available():
            logger.info("âœ… FFmpeg available")
        else:
            logger.warning("âš ï¸  FFmpeg not available - audio features may be limited")
    except Exception as e:
        logger.warning(f"âš ï¸  Could not check FFmpeg availability: {e}")
    
    logger.info(f"Base cycle interval: {BASE_CYCLE_INTERVAL}s ({BASE_CYCLE_INTERVAL//60} min)")
    logger.info("")
    logger.info("Schedule:")
    logger.info(f"  ğŸ“¥ Scraping:    every {CYCLE_CONFIG['scraping']} cycle(s)")
    logger.info(f"  ğŸ”„ Processing:  every {CYCLE_CONFIG['processing']} cycle(s)")
    logger.info(f"  ğŸ¨ Media:       every {CYCLE_CONFIG['media_generation']} cycle(s)")
    logger.info(f"  ğŸ“¤ Publishing:  every {CYCLE_CONFIG['publishing']} cycle(s)")
    logger.info(f"  ğŸ“» Broadcast:   every {CYCLE_CONFIG['broadcast']} cycle(s)")
    logger.info("â•"*70)
    
    # Setup signal handlers
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    # Import jobs
    try:
        import_jobs()
    except Exception as e:
        logger.error(f"âŒ Failed to import jobs: {e}")
        traceback.print_exc()
        sys.exit(1)
    
    cycle_number = 0
    
    while running:
        cycle_number += 1
        
        try:
            # Run the cycle
            run_cycle(cycle_number)
            
            if not running:
                break
            
            # Wait for next cycle
            logger.info(f"ğŸ’¤ Waiting {BASE_CYCLE_INTERVAL}s ({BASE_CYCLE_INTERVAL//60} min) until next cycle...")
            
            # Sleep in small increments to allow for graceful shutdown
            for _ in range(BASE_CYCLE_INTERVAL):
                if not running:
                    break
                time.sleep(1)
                
        except KeyboardInterrupt:
            logger.info("\nâš ï¸  Keyboard interrupt received")
            break
            
        except Exception as e:
            logger.error(f"âŒ Cycle error: {e}")
            traceback.print_exc()
            
            # Wait a bit before retrying
            logger.info("â³ Waiting 60s before retry...")
            for _ in range(60):
                if not running:
                    break
                time.sleep(1)
    
    logger.info("\n" + "â•"*70)
    logger.info("ğŸ›‘ Scheduler stopped gracefully")
    logger.info("â•"*70)


if __name__ == "__main__":
    main()