#!/usr/bin/env python3
"""
ğŸ™ï¸ Audio Transcription Job - Background Processing

ÙŠØ¹Ø§Ù„Ø¬ Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ù„ÙŠ status = 'pending' Ø£Ùˆ 'failed'
ÙˆÙŠØ­ÙˆÙ„Ù‡Ø§ Ù„Ù€ raw_news

Pipeline:
uploaded_files (pending/failed) â†’ STT â†’ Refiner â†’ Classifier â†’ raw_news
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import logging
from datetime import datetime
import psycopg2
from settings import DB_CONFIG

# Logging setup
log_dir = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'logs')
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(os.path.join(log_dir, 'audio_transcription.log'), encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Max retries before giving up
MAX_RETRIES = 3


def get_pending_audio_files():
    """
    Ø¬Ù„Ø¨ Ù…Ù„ÙØ§Øª Ø§Ù„ØµÙˆØª Ø§Ù„Ù„ÙŠ Ù…Ø­ØªØ§Ø¬Ø© Ù…Ø¹Ø§Ù„Ø¬Ø©
    """
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        # Ø¬Ù„Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª pending Ø£Ùˆ failed Ù…Ø¹ retry_count < MAX_RETRIES
        cursor.execute("""
            SELECT id, original_filename, file_path, file_type, retry_count
            FROM uploaded_files
            WHERE file_type = 'audio'
            AND (processing_status = 'pending' OR processing_status = 'failed')
            AND retry_count < %s
            ORDER BY created_at ASC
            LIMIT 10
        """, (MAX_RETRIES,))
        
        files = cursor.fetchall()
        cursor.close()
        conn.close()
        
        return [
            {
                'id': row[0],
                'original_filename': row[1],
                'file_path': row[2],
                'file_type': row[3],
                'retry_count': row[4] or 0
            }
            for row in files
        ]
        
    except Exception as e:
        logger.error(f"Error fetching pending files: {e}")
        return []


def update_file_status(file_id: int, status: str, error_msg: str = None, transcription: str = None, confidence: float = None):
    """
    ØªØ­Ø¯ÙŠØ« status Ø§Ù„Ù…Ù„Ù
    """
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        if status == 'failed':
            cursor.execute("""
                UPDATE uploaded_files
                SET processing_status = %s,
                    error_message = %s,
                    retry_count = retry_count + 1,
                    updated_at = NOW()
                WHERE id = %s
            """, (status, error_msg, file_id))
        elif status == 'completed':
            cursor.execute("""
                UPDATE uploaded_files
                SET processing_status = %s,
                    transcription = %s,
                    transcription_confidence = %s,
                    processed_at = NOW(),
                    updated_at = NOW()
                WHERE id = %s
            """, (status, transcription, confidence, file_id))
        else:
            cursor.execute("""
                UPDATE uploaded_files
                SET processing_status = %s,
                    updated_at = NOW()
                WHERE id = %s
            """, (status, file_id))
        
        conn.commit()
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"Error updating file status: {e}")
        return False


def check_news_exists(uploaded_file_id: int) -> bool:
    """
    ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹
    """
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        cursor.execute("""
            SELECT id FROM raw_news WHERE uploaded_file_id = %s
        """, (uploaded_file_id,))
        
        result = cursor.fetchone()
        cursor.close()
        conn.close()
        
        return result is not None
        
    except Exception as e:
        logger.error(f"Error checking news exists: {e}")
        return False


def save_news(title: str, content: str, tags: str, category: str, uploaded_file_id: int, original_text: str, source_type_id: int = 6):
    """
    Ø­ÙØ¸ Ø§Ù„Ø®Ø¨Ø± ÙÙŠ raw_news
    """
    try:
        import json
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        # Get category_id
        cursor.execute("SELECT id FROM categories WHERE name = %s", (category,))
        result = cursor.fetchone()
        category_id = result[0] if result else 7  # Default category
        
        cursor.execute("""
            INSERT INTO raw_news (
                title, content_text, tags, category_id, source_id, language_id,
                uploaded_file_id, original_text, source_type_id, metadata, collected_at
            )
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s::jsonb, NOW())
            RETURNING id
        """, (
            title, content, tags, category_id, None, 1,
            uploaded_file_id, original_text, source_type_id,
            json.dumps({'source_type': 'audio', 'processed_by': 'background_job'})
        ))
        
        news_id = cursor.fetchone()[0]
        conn.commit()
        cursor.close()
        conn.close()
        
        return news_id
        
    except Exception as e:
        logger.error(f"Error saving news: {e}")
        return None


def process_audio_file(file_info: dict) -> bool:
    """
    Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù ØµÙˆØªÙŠ ÙˆØ§Ø­Ø¯
    """
    file_id = file_info['id']
    file_path = file_info['file_path']
    retry_count = file_info['retry_count']
    
    logger.info(f"Processing file {file_id}: {file_info['original_filename']} (attempt {retry_count + 1})")
    
    # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ Ø§Ù„Ø®Ø¨Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ø§Ù‹
    if check_news_exists(file_id):
        logger.info(f"News already exists for file {file_id}, marking as completed")
        update_file_status(file_id, 'completed')
        return True
    
    try:
        # Import services
        from app.services.generators.stt_service import STTService
        from app.services.processing.news_refiner import NewsRefiner
        from app.services.processing.classifier import classify_with_gemini
        
        # Step 1: Transcribe
        logger.info(f"Step 1: Transcribing audio...")
        stt_service = STTService()
        stt_result = stt_service.transcribe_audio(file_path)
        
        if not stt_result.get('success'):
            error_msg = stt_result.get('error', 'STT failed')
            logger.error(f"STT failed for file {file_id}: {error_msg}")
            update_file_status(file_id, 'failed', error_msg)
            return False
        
        transcription = stt_result['text']
        confidence = stt_result.get('confidence', 0)
        logger.info(f"Transcription successful: {len(transcription)} chars, confidence: {confidence:.2%}")
        
        # Step 2: Refine
        logger.info(f"Step 2: Refining text...")
        refiner = NewsRefiner()
        refine_result = refiner.refine_to_news(transcription)
        
        if not refine_result.get('success'):
            error_msg = 'Refiner failed'
            logger.error(f"Refiner failed for file {file_id}")
            update_file_status(file_id, 'failed', error_msg)
            return False
        
        title = refine_result['title']
        content = refine_result['content']
        logger.info(f"Refined: {title[:50]}...")
        
        # Step 3: Classify
        logger.info(f"Step 3: Classifying...")
        category, tags_str, _, _ = classify_with_gemini(title, content)
        logger.info(f"Category: {category}")
        
        # Step 4: Save news
        logger.info(f"Step 4: Saving news...")
        news_id = save_news(
            title=title,
            content=content,
            tags=tags_str,
            category=category,
            uploaded_file_id=file_id,
            original_text=transcription,
            source_type_id=6  # Audio Upload
        )
        
        if not news_id:
            update_file_status(file_id, 'failed', 'Failed to save news')
            return False
        
        # Update file status
        update_file_status(file_id, 'completed', transcription=transcription, confidence=confidence)
        
        logger.info(f"âœ… Successfully processed file {file_id} â†’ news_id: {news_id}")
        return True
        
    except Exception as e:
        logger.error(f"Error processing file {file_id}: {e}")
        import traceback
        traceback.print_exc()
        update_file_status(file_id, 'failed', str(e))
        return False


def run_audio_transcription_job():
    """
    ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ job
    """
    logger.info("=" * 60)
    logger.info("ğŸ™ï¸ Starting Audio Transcription Job")
    logger.info("=" * 60)
    
    # Get pending files
    pending_files = get_pending_audio_files()
    
    if not pending_files:
        logger.info("No pending audio files to process")
        return {'processed': 0, 'success': 0, 'failed': 0}
    
    logger.info(f"Found {len(pending_files)} files to process")
    
    success_count = 0
    failed_count = 0
    
    for file_info in pending_files:
        try:
            if process_audio_file(file_info):
                success_count += 1
            else:
                failed_count += 1
        except Exception as e:
            logger.error(f"Unexpected error processing file {file_info['id']}: {e}")
            failed_count += 1
    
    logger.info("=" * 60)
    logger.info(f"ğŸ™ï¸ Audio Transcription Job Complete")
    logger.info(f"   Processed: {len(pending_files)}")
    logger.info(f"   Success: {success_count}")
    logger.info(f"   Failed: {failed_count}")
    logger.info("=" * 60)
    
    return {
        'processed': len(pending_files),
        'success': success_count,
        'failed': failed_count
    }


if __name__ == "__main__":
    run_audio_transcription_job()
