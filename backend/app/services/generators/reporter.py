#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
๐ฐ Report Generator Service - V2 (No JSON Parsing)
ุชูููุฏ ุงูุชูุงุฑูุฑ ุงูุฅุฎุจุงุฑูุฉ ูู clusters
ุงุณุชุฎุฏุงู format ูุตู ุจุณูุท ุจุฏู JSON
"""

import sys
import os

# Add project root to path to resolve module-not-found errors
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

import re
import time
from datetime import datetime, timezone
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import psycopg2
from google import genai

from settings import GEMINI_API_KEY, GEMINI_MODEL, DB_CONFIG


@dataclass
class ReportData:
    """ุจูุงูุงุช ุงูุชูุฑูุฑ ุงูููุณุชุฎุฑุฌุฉ"""
    title: str
    content: str
    
    def is_valid(self, min_words: int = 30, max_words: int = 300) -> Tuple[bool, str]:
        """ุงูุชุญูู ูู ุตุญุฉ ุงูุจูุงูุงุช"""
        if not self.title or len(self.title.strip()) < 10:
            return False, "ุงูุนููุงู ูุตูุฑ ุฌุฏุงู"
        
        if not self.content or len(self.content.strip()) < 30:
            return False, "ุงููุญุชูู ูุตูุฑ ุฌุฏุงู"
        
        word_count = len(self.content.split())
        if word_count < min_words:
            return False, f"ุนุฏุฏ ุงููููุงุช ({word_count}) ุฃูู ูู {min_words}"
        
        if word_count > max_words:
            return False, f"ุนุฏุฏ ุงููููุงุช ({word_count}) ุฃูุซุฑ ูู {max_words}"
        
        return True, "OK"


class TextParser:
    """ูุญูู ุงููุตูุต - ุงุณุชุฎุฑุงุฌ ุงูุนููุงู ูุงููุญุชูู"""
    
    @staticmethod
    def parse(text: str) -> Optional[ReportData]:
        """
        ุงุณุชุฎุฑุงุฌ ุงูุนููุงู ูุงููุญุชูู ูู ุงููุต
        ูุฌุฑุจ ุนุฏุฉ ุทุฑู ููุงุณุชุฎุฑุงุฌ
        """
        text = text.strip()
        
        # ุงูุทุฑููุฉ 1: ุงูุจุญุซ ุนู markers ูุงุถุญุฉ
        result = TextParser._parse_with_markers(text)
        if result:
            return result
        
        # ุงูุทุฑููุฉ 2: ุงูุจุญุซ ุนู ุฃููุงุท ุนุฑุจูุฉ
        result = TextParser._parse_arabic_format(text)
        if result:
            return result
        
        # ุงูุทุฑููุฉ 3: ุฃูู ุณุทุฑ = ุนููุงูุ ุงูุจุงูู = ูุญุชูู
        result = TextParser._parse_simple_split(text)
        if result:
            return result
        
        return None
    
    @staticmethod
    def _parse_with_markers(text: str) -> Optional[ReportData]:
        """ุงูุจุญุซ ุนู markers ูุซู [ุงูุนููุงู] ู [ุงููุญุชูู]"""
        patterns = [
            # Pattern 1: [ุงูุนููุงู] ... [ุงููุญุชูู] ...
            (r'\[ุงูุนููุงู\][:\s]*(.+?)(?=\[ุงููุญุชูู\])', r'\[ุงููุญุชูู\][:\s]*(.+)'),
            # Pattern 2: **ุงูุนููุงู:** ... **ุงููุญุชูู:** ...
            (r'\*\*ุงูุนููุงู\*\*[:\s]*(.+?)(?=\*\*ุงููุญุชูู\*\*)', r'\*\*ุงููุญุชูู\*\*[:\s]*(.+)'),
            # Pattern 3: ุงูุนููุงู: ... ุงููุญุชูู: ...
            (r'ุงูุนููุงู[:\s]+(.+?)(?=ุงููุญุชูู[:\s])', r'ุงููุญุชูู[:\s]+(.+)'),
            # Pattern 4: TITLE: ... CONTENT: ...
            (r'(?:TITLE|Title)[:\s]+(.+?)(?=(?:CONTENT|Content)[:\s])', r'(?:CONTENT|Content)[:\s]+(.+)'),
        ]
        
        for title_pattern, content_pattern in patterns:
            title_match = re.search(title_pattern, text, re.DOTALL | re.IGNORECASE)
            content_match = re.search(content_pattern, text, re.DOTALL | re.IGNORECASE)
            
            if title_match and content_match:
                title = TextParser._clean_text(title_match.group(1))
                content = TextParser._clean_text(content_match.group(1))
                
                if title and content:
                    return ReportData(title=title, content=content)
        
        return None
    
    @staticmethod
    def _parse_arabic_format(text: str) -> Optional[ReportData]:
        """ุงูุจุญุซ ุนู format ุนุฑุจู"""
        # ุงูุจุญุซ ุนู ุณุทุฑ ูุจุฏุฃ ุจู "ุนููุงู" ุฃู ูุญุชูู ุนูู ":"
        lines = text.split('\n')
        title = None
        content_lines = []
        content_started = False
        
        for i, line in enumerate(lines):
            line = line.strip()
            if not line:
                continue
            
            # ุงูุจุญุซ ุนู ุงูุนููุงู
            if not title:
                # ุฅุฒุงูุฉ ุฃู prefix
                cleaned = re.sub(r'^(ุงูุนููุงู|ุนููุงู|Title)[:\s\-โโ]*', '', line, flags=re.IGNORECASE)
                cleaned = re.sub(r'^\*+|\*+$', '', cleaned).strip()
                cleaned = re.sub(r'^#+\s*', '', cleaned).strip()
                
                if cleaned and len(cleaned) > 10:
                    title = cleaned
                    continue
            
            # ุจุนุฏ ุงูุนููุงูุ ูุฌูุน ุงููุญุชูู
            if title:
                # ุชุฎุทู ุฃู marker ูููุญุชูู
                if re.match(r'^(ุงููุญุชูู|ูุญุชูู|Content)[:\s]*$', line, re.IGNORECASE):
                    content_started = True
                    continue
                
                content_started = True
                # ุฅุฒุงูุฉ prefix ุงููุญุชูู ุฅุฐุง ูุฌุฏ
                cleaned = re.sub(r'^(ุงููุญุชูู|ูุญุชูู|Content)[:\s\-โโ]*', '', line, flags=re.IGNORECASE)
                if cleaned:
                    content_lines.append(cleaned)
        
        if title and content_lines:
            content = '\n'.join(content_lines)
            content = TextParser._clean_text(content)
            if content:
                return ReportData(title=title, content=content)
        
        return None
    
    @staticmethod
    def _parse_simple_split(text: str) -> Optional[ReportData]:
        """ุฃุจุณุท ุทุฑููุฉ: ุฃูู ุณุทุฑ = ุนููุงู"""
        # ุฅุฒุงูุฉ markdown
        text = re.sub(r'```[\s\S]*?```', '', text)
        text = re.sub(r'^\s*#+ ', '', text, flags=re.MULTILINE)
        
        lines = [l.strip() for l in text.split('\n') if l.strip()]
        
        if len(lines) < 2:
            return None
        
        # ุฃูู ุณุทุฑ ุบูุฑ ูุงุฑุบ = ุนููุงู
        title = lines[0]
        title = re.sub(r'^\*+|\*+$', '', title).strip()
        title = re.sub(r'^[""]|[""]$', '', title).strip()
        
        # ุงูุจุงูู = ูุญุชูู
        content = '\n'.join(lines[1:])
        content = TextParser._clean_text(content)
        
        if title and content and len(title) > 10:
            return ReportData(title=title, content=content)
        
        return None
    
    @staticmethod
    def _clean_text(text: str) -> str:
        """ุชูุธูู ุงููุต"""
        if not text:
            return ""
        
        # ุฅุฒุงูุฉ markdown
        text = re.sub(r'\*\*|\*|__|_', '', text)
        text = re.sub(r'```[\s\S]*?```', '', text)
        text = re.sub(r'`[^`]+`', '', text)
        
        # ุฅุฒุงูุฉ HTML
        text = re.sub(r'<[^>]+>', '', text)
        
        # ุฅุฒุงูุฉ JSON artifacts
        text = re.sub(r'[{}\[\]]', '', text)
        text = re.sub(r'"title"\s*:', '', text)
        text = re.sub(r'"content"\s*:', '', text)
        
        # ุชูุธูู ุงููุณุงูุงุช
        text = re.sub(r'\n{3,}', '\n\n', text)
        text = re.sub(r' {2,}', ' ', text)
        
        return text.strip()


class ReportGenerator:
    """ูููุฏ ุงูุชูุงุฑูุฑ ุงูุฅุฎุจุงุฑูุฉ"""
    
    def __init__(self):
        """ุชููุฆุฉ ุงููููุฏ"""
        self.conn = None
        self.cursor = None
        self.parser = TextParser()
        
        # ุงุชุตุงู ุจูุงุนุฏุฉ ุงูุจูุงูุงุช
        try:
            self.conn = psycopg2.connect(**DB_CONFIG)
            self.cursor = self.conn.cursor()
            print("โ ReportGenerator initialized")
        except Exception as e:
            print(f"โ Database connection failed: {e}")
            raise
        
        # ุชููุฆุฉ Gemini
        try:
            self.client = genai.Client(api_key=GEMINI_API_KEY)
            print(f"โ Gemini client ready (Model: {GEMINI_MODEL})")
        except Exception as e:
            print(f"โ Gemini client failed: {e}")
            raise
        
    def generate_reports_for_clusters(
        self,
        cluster_ids: List[int] = None,
        skip_existing: bool = True,
        check_updates_hours: int = 1
    ) -> Dict:
        """ุฅูุดุงุก ุชูุงุฑูุฑ ูู clusters"""
        print("\n" + "="*70)
        print("๐ค Starting Report Generation (V2 - Text Format)")
        print("="*70)

        # ุฌูุจ clusters
        if cluster_ids:
            clusters = self._fetch_clusters_by_ids(cluster_ids)
        else:
            # 1๏ธโฃ ููุณุชุฑุงุช ุฌุฏูุฏุฉ ุจุฏูู ุชูุงุฑูุฑ
            new_clusters = self._fetch_clusters_without_reports() if skip_existing else []

            # 2๏ธโฃ ููุณุชุฑุงุช ูุญุฏุซุฉ ุชุญุชุงุฌ ุฅุนุงุฏุฉ ุชูููุฏ
            updated_clusters = self._fetch_recently_updated_clusters(check_updates_hours)

            # ุฏูุฌ ุงููุงุฆูุชูู (ุจุฏูู ุชูุฑุงุฑ)
            seen_ids = set()
            clusters = []
            for c in new_clusters + updated_clusters:
                if c['id'] not in seen_ids:
                    clusters.append(c)
                    seen_ids.add(c['id'])

            print(f"   ๐ฐ New clusters: {len(new_clusters)}")
            print(f"   ๐ Updated clusters: {len(updated_clusters)}")

        if not clusters:
            print("๐ญ No clusters to process")
            return {'total': 0, 'success': 0, 'failed': 0}

        print(f"๐ Processing {len(clusters)} clusters...")

        stats = {'total': len(clusters), 'success': 0, 'failed': 0}

        for i, cluster in enumerate(clusters, 1):
            cluster_id = cluster['id']
            print(f"\n[{i}/{len(clusters)}] Cluster #{cluster_id}")

            gen_time = self._generate_report_for_cluster(cluster)

            if gen_time:
                stats['success'] += 1
                print(f"   โ Done in {gen_time:.2f}s")
            else:
                stats['failed'] += 1
                print(f"   โ Failed")

        print(f"\n{'='*70}")
        print(f"๐ Results: {stats['success']} success, {stats['failed']} failed")
        print(f"{'='*70}")

        return stats

    def _generate_report_for_cluster(self, cluster: Dict) -> Optional[float]:
        """ุฅูุดุงุก ุชูุฑูุฑ ูู cluster ูุงุญุฏ"""
        cluster_id = cluster['id']

        news_items = self._fetch_cluster_news(cluster_id)

        if not news_items:
            print("   โ๏ธ  No news found")
            return None

        print(f"   ๐ฐ Found {len(news_items)} news items")

        prompt = self._get_report_prompt(cluster, news_items)

        ai_start = time.time()
        report_data = self._call_gemini(prompt)
        generation_time = time.time() - ai_start

        if not report_data:
            return None

        word_count = len(report_data.content.split())
        print(f"   ๐ Generated: {word_count} words")

        success = self._save_report(
            cluster_id=cluster_id,
            title=report_data.title,
            content=report_data.content,
            source_news_count=len(news_items)
        )

        return generation_time if success else None

    def _get_report_prompt(self, cluster: Dict, news_items: List[Dict]) -> str:
        """ุฅูุดุงุก ุจุฑููุจุช ุงูุชูุฑูุฑ - ุจุฏูู JSON"""
        news_texts = []
        for idx, news in enumerate(news_items, 1):
            news_texts.append(f"""
[ุฎุจุฑ {idx}]
ุงูุนููุงู: {news['title']}
ุงููุญุชูู: {news['content'][:800]}...
ุงููุตุฏุฑ: {news.get('source_name', 'ุบูุฑ ูุนุฑูู')}
""")

        combined_news = "\n---\n".join(news_texts)

        category = cluster.get('category_name', 'ุฃุฎุจุงุฑ')
        tags = cluster.get('tags', [])
        tags_str = "ุ ".join(tags[:8]) if tags else ""

        # โ Prompt ุจุณูุท ุจุฏูู JSON
        prompt = f"""ุฃูุช ุตุญูู ููุณุทููู ูุญุชุฑู. ุงูุชุจ ุชูุฑูุฑุงู ุฅุฎุจุงุฑูุงู ูู ุงูุฃุฎุจุงุฑ ุงูุชุงููุฉ:

{combined_news}

ุงูุชุตููู: {category}
ุงููููุงุช ุงูููุชุงุญูุฉ: {tags_str}

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ุงููุทููุจ: ุงูุชุจ ุชูุฑูุฑุงู ุจุงูุดูู ุงูุชุงูู ุจุงูุถุจุท:
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

[ุงูุนููุงู]
ุงูุชุจ ุนููุงู ุฌุฐุงุจ ูู 10-15 ูููุฉ

[ุงููุญุชูู]
ุงูุชุจ ุงูุชูุฑูุฑ ููุง ( 30 ู 90 ูููุฉ ุชูุฑูุจุงู)
- ุงุจุฏุฃ ุจููุฑุฉ ุชุฌูุจ ุนูู: ููุ ูุงุฐุงุ ูุชูุ ุฃููุ ููุงุฐุง
- 3-5 ููุฑุงุช ููุธูุฉ
- ูุบุฉ ุตุญููุฉ ุงุญุชุฑุงููุฉ
- ุนุฑุจูุฉ ูุตุญู ูุงุถุญุฉ
- ูุง ุชุฐูุฑ "ุญุณุจ ุงููุตุงุฏุฑ" ุฃู ุฃุณูุงุก ุงููุตุงุฏุฑ
- ูุง ุชุฎุชุฑุน ูุนูููุงุช

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ูุซุงู ุนูู ุงูุดูู ุงููุทููุจ:
โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ

[ุงูุนููุงู]
ุบุงุฑุงุช ุฅุณุฑุงุฆูููุฉ ุนูู ุบุฒุฉ ุชููุน ุนุดุฑุงุช ุงูุดูุฏุงุก ูุณุท ุชุตุงุนุฏ ุงูุนูููุงุช ุงูุนุณูุฑูุฉ

[ุงููุญุชูู]
ุดูุช ููุงุช ุงูุงุญุชูุงู ุงูุฅุณุฑุงุฆููู ุณูุณูุฉ ูู ุงูุบุงุฑุงุช ุงูุฌููุฉ ุนูู ูุทุงุน ุบุฒุฉ...

โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
ุงูุขู ุงูุชุจ ุงูุชูุฑูุฑ:
"""

        return prompt

    def _call_gemini(self, prompt: str, min_words: int = 30, max_words: int = 300, retries: int = 3) -> Optional[ReportData]:
        """ุงุณุชุฏุนุงุก Gemini ูุงุณุชุฎุฑุงุฌ ุงูุจูุงูุงุช"""
        for attempt in range(retries):
            try:
                response = self.client.models.generate_content(
                    model=GEMINI_MODEL,
                    contents=prompt,
                    config={
                        'temperature': 0.7,
                        'max_output_tokens': 2048
                    }
                )

                result_text = response.text.strip()

                # ุงุณุชุฎุฑุงุฌ ุงูุจูุงูุงุช ุจุงุณุชุฎุฏุงู ุงูู parser
                report_data = self.parser.parse(result_text)

                if not report_data:
                    print(f"   โ๏ธ  Could not parse response, attempt {attempt + 1}/{retries}")
                    print(f"   ๐ Preview: {result_text[:200]}...")
                    time.sleep(2)
                    continue

                # ุงูุชุญูู ูู ุงูุตุญุฉ
                is_valid, reason = report_data.is_valid(min_words, max_words)

                if not is_valid:
                    print(f"   โ๏ธ  {reason}, attempt {attempt + 1}/{retries}")
                    time.sleep(2)
                    continue

                return report_data

            except Exception as e:
                print(f"   โ๏ธ  Error: {str(e)[:100]}, attempt {attempt + 1}/{retries}")
                time.sleep(2)

                if attempt == retries - 1:
                    print(f"   โ Generation failed after {retries} attempts")
                    return None

        return None

    def _fetch_recently_updated_clusters(self, hours: int = 1) -> List[Dict]:
        """
        ุฌูุจ ุงูููุณุชุฑุงุช ุงูุชู ุชู ุชุญุฏูุซูุง ุฎูุงู ุขุฎุฑ X ุณุงุนุฉ
        ูุงูุชู ูุฏููุง ุชูุงุฑูุฑ ูุฏููุฉ (ุงูุชูุฑูุฑ ุฃูุฏู ูู ุชุญุฏูุซ ุงูููุณุชุฑ)
        """
        query = """
            SELECT 
                nc.id, nc.description, nc.tags, nc.category_id,
                c.name as category_name, nc.news_count, nc.created_at
            FROM news_clusters nc
            LEFT JOIN categories c ON nc.category_id = c.id
            INNER JOIN generated_report gr ON nc.id = gr.cluster_id
            WHERE nc.updated_at >= NOW() - INTERVAL '%s hours'
              AND nc.updated_at > gr.updated_at
            ORDER BY nc.updated_at DESC
            LIMIT 50;
        """
        self.cursor.execute(query, (hours,))
        return self._parse_clusters(self.cursor.fetchall())

    def _fetch_clusters_without_reports(self) -> List[Dict]:
        """ุฌูุจ ุงูููุณุชุฑุงุช ุงูุชู ููุณ ููุง ุชูุงุฑูุฑ"""
        query = """
            SELECT 
                nc.id, nc.description, nc.tags, nc.category_id,
                c.name as category_name, nc.news_count, nc.created_at
            FROM news_clusters nc
            LEFT JOIN categories c ON nc.category_id = c.id
            LEFT JOIN generated_report gr ON nc.id = gr.cluster_id
            WHERE gr.id IS NULL
            ORDER BY nc.created_at DESC
            LIMIT 100;
        """
        self.cursor.execute(query)
        return self._parse_clusters(self.cursor.fetchall())

    def _fetch_clusters_by_ids(self, cluster_ids: List[int]) -> List[Dict]:
        """ุฌูุจ ุงูููุณุชุฑุงุช ุจูุงุณุทุฉ IDs"""
        if not cluster_ids:
            return []
        query = """
            SELECT 
                nc.id, nc.description, nc.tags, nc.category_id,
                c.name as category_name, nc.news_count, nc.created_at
            FROM news_clusters nc
            LEFT JOIN categories c ON nc.category_id = c.id
            WHERE nc.id = ANY(%s)
        """
        self.cursor.execute(query, (cluster_ids,))
        return self._parse_clusters(self.cursor.fetchall())

    def _fetch_cluster_news(self, cluster_id: int) -> List[Dict]:
        """ุฌูุจ ุฃุฎุจุงุฑ cluster ูุนูู"""
        query = """
            SELECT 
                rn.id, rn.title, rn.content_text as content, s.name as source_name
            FROM raw_news rn
            JOIN news_cluster_members ncm ON rn.id = ncm.news_id
            LEFT JOIN sources s ON rn.source_id = s.id
            WHERE ncm.cluster_id = %s
            ORDER BY rn.published_at DESC
            LIMIT 20;
        """
        self.cursor.execute(query, (cluster_id,))
        columns = [desc[0] for desc in self.cursor.description]
        return [dict(zip(columns, row)) for row in self.cursor.fetchall()]

    def _parse_clusters(self, rows: List[Tuple]) -> List[Dict]:
        """ุชุญููู ูุชุงุฆุฌ query ุงูููุณุชุฑุงุช ุฅูู dict"""
        columns = [desc[0] for desc in self.cursor.description]
        return [dict(zip(columns, row)) for row in rows]

    def _save_report(self, cluster_id: int, title: str, content: str, source_news_count: int) -> bool:
        """ุญูุธ ุงูุชูุฑูุฑ ูู ูุงุนุฏุฉ ุงูุจูุงูุงุช"""
        try:
            query = """
                INSERT INTO generated_report (cluster_id, title, content, source_news_count, status, published_at, created_at, updated_at)
                VALUES (%s, %s, %s, %s, 'draft', NOW(), NOW(), NOW())
                ON CONFLICT (cluster_id) DO UPDATE SET
                    title = EXCLUDED.title, content = EXCLUDED.content, source_news_count = EXCLUDED.source_news_count,
                    status = 'draft', updated_at = NOW();
            """
            self.cursor.execute(query, (cluster_id, title, content, source_news_count))
            self.conn.commit()
            return True
        except Exception as e:
            print(f"   โ Error saving report: {e}")
            self.conn.rollback()
            return False


# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
# ููุงุฎุชุจุงุฑ
# โโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโโ
if __name__ == "__main__":
    # ุงุฎุชุจุงุฑ ุงูู Parser
    test_texts = [
        """
[ุงูุนููุงู]
ุบุงุฑุงุช ุฅุณุฑุงุฆูููุฉ ููุซูุฉ ุนูู ูุทุงุน ุบุฒุฉ ุชููุน ุนุดุฑุงุช ุงูุดูุฏุงุก

[ุงููุญุชูู]
ุดูุช ููุงุช ุงูุงุญุชูุงู ุงูุฅุณุฑุงุฆููู ูุฌุฑ ุงูููู ุณูุณูุฉ ูู ุงูุบุงุฑุงุช ุงูุฌููุฉ ุงูุนูููุฉ ุนูู ููุงุทู ูุชูุฑูุฉ ูู ูุทุงุน ุบุฒุฉุ ูุง ุฃุณูุฑ ุนู ุงุณุชุดูุงุฏ ุนุดุฑุงุช ุงูููุงุทููู ูุฅุตุงุจุฉ ุงูุนุดุฑุงุช ุงูุขุฎุฑูู.

ููุฏ ุงุณุชูุฏูุช ุงูุบุงุฑุงุช ููุงุทู ุณูููุฉ ูู ูุฏููุฉ ุบุฒุฉ ูุฎุงู ูููุณ ูุฑูุญุ ุญูุซ ุฏูุฑุช ุนุฏุฏุงู ูู ุงูููุงุฒู ูุงููุจุงูู ุงูุณูููุฉ. ูุฃูุงุฏุช ุงููุตุงุฏุฑ ุงูุทุจูุฉ ุจูุตูู ุฃุนุฏุงุฏ ูุจูุฑุฉ ูู ุงูุดูุฏุงุก ูุงูุฌุฑุญู ุฅูู ุงููุณุชุดููุงุช.

ููู ุงูุณูุงู ุฐุงุชูุ ุฃุนููุช ูุตุงุฆู ุงูููุงููุฉ ุงูููุณุทูููุฉ ุนู ุงุณุชูุฑุงุฑูุง ูู ุงูุชุตุฏู ููุนุฏูุงู ุงูุฅุณุฑุงุฆูููุ ูุคูุฏุฉ ุฌููุฒูุชูุง ููุฏูุงุน ุนู ุงูุดุนุจ ุงูููุณุทููู.
        """,
        """
ุงูุนููุงู: ุชุตุงุนุฏ ุงูุชูุชุฑ ูู ุงูุถูุฉ ุงูุบุฑุจูุฉ
ุงููุญุชูู: ุดูุฏุช ูุฏู ุงูุถูุฉ ุงูุบุฑุจูุฉ ุงูููู ุชุตุงุนุฏุงู ูู ุงูููุงุฌูุงุช...
        """,
        """
**ุนููุงู ุงูุชูุฑูุฑ**
ุฃุญุฏุงุซ ูุชุณุงุฑุนุฉ ูู ุงูููุทูุฉ

ูุฐุง ูู ูุต ุงููุญุชูู ุงููุงูู ููุชูุฑูุฑ ุงูุฐู ูุชุญุฏุซ ุนู ุงูุฃุญุฏุงุซ...
        """
    ]
    
    parser = TextParser()
    
    for i, text in enumerate(test_texts, 1):
        print(f"\n{'='*50}")
        print(f"Test {i}:")
        result = parser.parse(text)
        if result:
            print(f"โ Title: {result.title[:50]}...")
            print(f"โ Content: {result.content[:100]}...")
            valid, reason = result.is_valid()
            print(f"โ Valid: {valid} - {reason}")
        else:
            print("โ Failed to parse")