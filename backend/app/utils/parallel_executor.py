#!/usr/bin/env python3
"""
ðŸ”„ Parallel Job Executor
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ÙŠØ´ØºÙ„ Ø§Ù„Ù€ jobs Ø¨Ø´ÙƒÙ„ parallel Ù…Ø¹ timeout ÙˆØ¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
ÙŠØ¶Ù…Ù† Ø¥Ù† job ÙˆØ§Ø­Ø¯ Ù…Ø§ ÙŠØ¹Ø·Ù„ Ø§Ù„Ø¨Ø§Ù‚ÙŠ

Features:
- Parallel execution Ù…Ø¹ threading
- Individual timeouts Ù„ÙƒÙ„ job
- Error isolation (job ÙˆØ§Ø­Ø¯ ÙŠÙØ´Ù„ Ù…Ø§ ÙŠØ£Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø§Ù‚ÙŠ)
- Progress monitoring
- Graceful shutdown
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import threading
import time
import logging
from typing import Dict, List, Callable, Any, Optional
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, Future, as_completed
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class JobConfig:
    """Configuration for a single job"""
    name: str
    func: Callable
    timeout: int = 300  # 5 Ø¯Ù‚Ø§Ø¦Ù‚ default
    retry_count: int = 0
    dependencies: List[str] = None  # jobs ÙŠØ¬Ø¨ ØªØ®Ù„Øµ Ù‚Ø¨Ù„ Ù‡Ø°Ø§
    
    def __post_init__(self):
        if self.dependencies is None:
            self.dependencies = []


@dataclass
class JobResult:
    """Result of job execution"""
    name: str
    success: bool
    duration: float
    result: Dict[str, Any]
    error: Optional[str] = None
    timeout: bool = False
    retries: int = 0


class ParallelJobExecutor:
    """
    Executor Ù„Ù„Ù€ jobs Ø¨Ø´ÙƒÙ„ parallel Ù…Ø¹ dependency management
    """
    
    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.jobs: Dict[str, JobConfig] = {}
        self.results: Dict[str, JobResult] = {}
        self.running_jobs: Dict[str, Future] = {}
        self.completed_jobs: set = set()
        self.failed_jobs: set = set()
        
    def add_job(self, job_config: JobConfig):
        """Ø¥Ø¶Ø§ÙØ© job Ù„Ù„Ù€ executor"""
        self.jobs[job_config.name] = job_config
        logger.info(f"ðŸ“ Added job: {job_config.name} (timeout: {job_config.timeout}s)")
    
    def can_run_job(self, job_name: str) -> bool:
        """ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ Ø§Ù„Ù€ job Ù…Ù…ÙƒÙ† ÙŠØ´ØªØºÙ„ (dependencies Ù…ÙƒØªÙ…Ù„Ø©)"""
        job = self.jobs[job_name]
        
        # ØªØ­Ù‚Ù‚ Ø¥Ù† ÙƒÙ„ Ø§Ù„Ù€ dependencies Ø®Ù„ØµØª Ø¨Ù†Ø¬Ø§Ø­
        for dep in job.dependencies:
            if dep not in self.completed_jobs:
                return False
        
        return True
    
    def run_single_job(self, job_config: JobConfig) -> JobResult:
        """ØªØ´ØºÙŠÙ„ job ÙˆØ§Ø­Ø¯ Ù…Ø¹ timeout"""
        start_time = datetime.now()
        job_name = job_config.name
        
        logger.info(f"â–¶ï¸  Starting job: {job_name}")
        
        def target():
            try:
                return job_config.func()
            except Exception as e:
                return {'error': str(e)}
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ job ÙÙŠ thread Ù…Ù†ÙØµÙ„ Ù…Ø¹ timeout
        executor = ThreadPoolExecutor(max_workers=1)
        future = executor.submit(target)
        
        try:
            # Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù†ØªÙŠØ¬Ø© Ù…Ø¹ timeout
            result = future.result(timeout=job_config.timeout)
            duration = (datetime.now() - start_time).total_seconds()
            
            if result.get('error'):
                logger.error(f"âŒ {job_name} failed: {result['error']}")
                return JobResult(
                    name=job_name,
                    success=False,
                    duration=duration,
                    result=result,
                    error=result['error']
                )
            else:
                logger.info(f"âœ… {job_name} completed in {duration:.1f}s")
                return JobResult(
                    name=job_name,
                    success=True,
                    duration=duration,
                    result=result
                )
                
        except TimeoutError:
            duration = (datetime.now() - start_time).total_seconds()
            error_msg = f"Job timed out after {job_config.timeout}s"
            logger.error(f"â°âŒ {job_name}: {error_msg}")
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù€ job
            future.cancel()
            
            return JobResult(
                name=job_name,
                success=False,
                duration=duration,
                result={'error': error_msg},
                error=error_msg,
                timeout=True
            )
            
        except Exception as e:
            duration = (datetime.now() - start_time).total_seconds()
            logger.error(f"âŒ {job_name} crashed: {e}")
            
            return JobResult(
                name=job_name,
                success=False,
                duration=duration,
                result={'error': str(e)},
                error=str(e)
            )
        
        finally:
            executor.shutdown(wait=False)
    
    def execute_all(self) -> Dict[str, JobResult]:
        """
        ØªØ´ØºÙŠÙ„ ÙƒÙ„ Ø§Ù„Ù€ jobs Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ø§Ù„Ù€ dependencies
        """
        logger.info("=" * 60)
        logger.info(f"ðŸš€ Starting parallel execution of {len(self.jobs)} jobs")
        logger.info(f"Max workers: {self.max_workers}")
        logger.info("=" * 60)
        
        start_time = datetime.now()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            
            while len(self.completed_jobs) + len(self.failed_jobs) < len(self.jobs):
                
                # Ø§Ø¨Ø­Ø« Ø¹Ù† jobs Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„ØªØ´ØºÙŠÙ„
                ready_jobs = []
                for job_name, job_config in self.jobs.items():
                    if (job_name not in self.completed_jobs and 
                        job_name not in self.failed_jobs and 
                        job_name not in self.running_jobs and
                        self.can_run_job(job_name)):
                        ready_jobs.append(job_config)
                
                # Ø´ØºÙ„ Ø§Ù„Ù€ jobs Ø§Ù„Ø¬Ø§Ù‡Ø²Ø©
                for job_config in ready_jobs:
                    if len(self.running_jobs) < self.max_workers:
                        future = executor.submit(self.run_single_job, job_config)
                        self.running_jobs[job_config.name] = future
                        logger.info(f"ðŸ”„ Submitted job: {job_config.name}")
                
                # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù€ jobs Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø©
                completed_futures = []
                for job_name, future in self.running_jobs.items():
                    if future.done():
                        completed_futures.append(job_name)
                
                # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                for job_name in completed_futures:
                    future = self.running_jobs.pop(job_name)
                    result = future.result()
                    self.results[job_name] = result
                    
                    if result.success:
                        self.completed_jobs.add(job_name)
                    else:
                        self.failed_jobs.add(job_name)
                
                # Ø§Ù†ØªØ¸Ø§Ø± Ù‚ØµÙŠØ± Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰
                if not completed_futures and not ready_jobs:
                    time.sleep(1)
        
        total_duration = (datetime.now() - start_time).total_seconds()
        
        # Ù…Ù„Ø®Øµ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        logger.info("=" * 60)
        logger.info(f"ðŸ Parallel execution completed in {total_duration:.1f}s")
        logger.info(f"âœ… Successful: {len(self.completed_jobs)}")
        logger.info(f"âŒ Failed: {len(self.failed_jobs)}")
        logger.info("=" * 60)
        
        for job_name, result in self.results.items():
            status = "âœ…" if result.success else "âŒ"
            timeout_info = " (TIMEOUT)" if result.timeout else ""
            logger.info(f"  {status} {job_name}: {result.duration:.1f}s{timeout_info}")
        
        logger.info("=" * 60)
        
        return self.results


# =============================================================================
# Helper Functions
# =============================================================================

def create_job_group(jobs: List[tuple], max_workers: int = 4) -> ParallelJobExecutor:
    """
    Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù…ÙˆØ¹Ø© jobs Ù„Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ
    
    Args:
        jobs: Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† (name, func, timeout, dependencies)
        max_workers: Ø¹Ø¯Ø¯ Ø§Ù„Ù€ workers Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©
    
    Returns:
        ParallelJobExecutor: executor Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØ´ØºÙŠÙ„
    """
    executor = ParallelJobExecutor(max_workers=max_workers)
    
    for job_info in jobs:
        if len(job_info) == 2:
            name, func = job_info
            timeout = 300
            dependencies = []
        elif len(job_info) == 3:
            name, func, timeout = job_info
            dependencies = []
        elif len(job_info) == 4:
            name, func, timeout, dependencies = job_info
        else:
            raise ValueError(f"Invalid job info: {job_info}")
        
        job_config = JobConfig(
            name=name,
            func=func,
            timeout=timeout,
            dependencies=dependencies
        )
        executor.add_job(job_config)
    
    return executor


def run_jobs_parallel(jobs: List[tuple], max_workers: int = 4) -> Dict[str, JobResult]:
    """
    ØªØ´ØºÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© jobs Ø¨Ø´ÙƒÙ„ Ù…ØªÙˆØ§Ø²ÙŠ
    
    Args:
        jobs: Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† (name, func, timeout, dependencies)
        max_workers: Ø¹Ø¯Ø¯ Ø§Ù„Ù€ workers Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©
    
    Returns:
        Dict[str, JobResult]: Ù†ØªØ§Ø¦Ø¬ ÙƒÙ„ Ø§Ù„Ù€ jobs
    """
    executor = create_job_group(jobs, max_workers)
    return executor.execute_all()