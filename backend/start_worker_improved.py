#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
üîÑ Sequential Pipeline Scheduler with Cycle Pattern
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
ŸÜÿ∏ÿßŸÖ ÿØŸàÿ±ÿßÿ™ ŸÖÿ™ÿ™ÿßŸÑŸäÿ©:
- ÿØŸàÿ±ÿ™ŸäŸÜ ÿ£ÿ≥ÿßÿ≥Ÿäÿ™ŸäŸÜ (Main Cycle) 
- ÿØŸàÿ±ÿ© Ÿàÿßÿ≠ÿØÿ© ŸÑŸÑŸÜÿ¥ÿ±ÿ© (Broadcast Cycle)
- ÿ´ŸÖ ŸäÿπŸäÿØ ÿßŸÑŸÜŸÖÿ∑

Main Cycle (Sequential):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. üì• Scraping (ÿ¨ŸÖÿπ ÿßŸÑÿ£ÿÆÿ®ÿßÿ±)                               ‚îÇ
‚îÇ  2. üîÑ Clustering (ÿ™ÿ¨ŸÖŸäÿπ ÿßŸÑÿ£ÿÆÿ®ÿßÿ±)                          ‚îÇ
‚îÇ  3. üìù Social Media Generation (ÿ™ŸàŸÑŸäÿØ ŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑÿ≥Ÿàÿ¥ÿßŸÑ ŸÖŸäÿØŸäÿß)   ‚îÇ
‚îÇ  4. üñºÔ∏è Image Generation (ÿ™ŸàŸÑŸäÿØ ÿßŸÑÿµŸàÿ±)                      ‚îÇ
‚îÇ  5. üéµ Audio Generation (ÿ™ŸàŸÑŸäÿØ ÿßŸÑÿµŸàÿ™)                      ‚îÇ
‚îÇ  6. üì± Social Media Image Generation (ÿµŸàÿ± ÿßŸÑÿ≥Ÿàÿ¥ÿßŸÑ ŸÖŸäÿØŸäÿß)    ‚îÇ
‚îÇ  7. üé¨ Reel Generation (ÿ™ŸàŸÑŸäÿØ ÿßŸÑÿ±ŸäŸÑÿ≤)                       ‚îÇ
‚îÇ  8. üì§ Publishing (ÿßŸÑŸÜÿ¥ÿ±)                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Broadcast Cycle:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üìª Broadcast Generation (ÿ™ŸàŸÑŸäÿØ ÿßŸÑŸÜÿ¥ÿ±ÿ© ŸàÿßŸÑŸÖŸàÿ¨ÿ≤)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Pattern: Main ‚Üí Main ‚Üí Broadcast ‚Üí Main ‚Üí Main ‚Üí Broadcast...
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""

import os
import sys
import time
import signal
import logging
import traceback
from datetime import datetime, timezone
from typing import Dict, Optional

import certifi
import psycopg2

# Set SSL certificate
os.environ["SSL_CERT_FILE"] = certifi.where()

# Add path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from settings import DB_CONFIG
from app.utils.parallel_executor import ParallelJobExecutor, JobConfig, run_jobs_parallel
from app.utils.job_timeout import timeout_job_by_type, get_job_timeout

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Logging Setup
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

log_dir = 'logs'
os.makedirs(log_dir, exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(f'{log_dir}/worker_improved.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Job Imports (Lazy Loading)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def import_jobs():
    """Import all job functions with timeout decorators"""
    global scrape_news, cluster_news, generate_reports
    global generate_social_media_content, generate_images, generate_audio
    global generate_social_media_images, generate_reels, publish_to_social_media
    global generate_all_broadcasts, run_audio_transcription_job
    
    # Import original functions
    from app.jobs.scraper_job import scrape_news as _scrape_news
    from app.jobs.clustering_job import cluster_news as _cluster_news
    from app.jobs.reports_job import generate_reports as _generate_reports
    from app.jobs.social_media_job import generate_social_media_content as _generate_social_media_content
    from app.jobs.image_generation_job import generate_images as _generate_images
    from app.jobs.audio_generation_job import generate_audio as _generate_audio
    from app.jobs.social_media_image_job import generate_social_media_images as _generate_social_media_images
    from app.jobs.reel_generation_job import generate_reels as _generate_reels
    from app.jobs.publishers_job import publish_to_social_media as _publish_to_social_media
    from app.jobs.broadcast_job import generate_all_broadcasts as _generate_all_broadcasts
    from app.jobs.audio_transcription_job import run_audio_transcription_job as _run_audio_transcription_job
    
    # Wrap with timeout decorators
    scrape_news = timeout_job_by_type('scraping')(_scrape_news)
    cluster_news = timeout_job_by_type('clustering')(_cluster_news)
    generate_reports = timeout_job_by_type('reports')(_generate_reports)
    generate_social_media_content = timeout_job_by_type('social_media')(_generate_social_media_content)
    generate_images = timeout_job_by_type('images')(_generate_images)
    generate_audio = timeout_job_by_type('audio')(_generate_audio)
    generate_social_media_images = timeout_job_by_type('images')(_generate_social_media_images)
    generate_reels = timeout_job_by_type('video')(_generate_reels)
    publish_to_social_media = timeout_job_by_type('publishing')(_publish_to_social_media)
    generate_all_broadcasts = timeout_job_by_type('broadcast')(_generate_all_broadcasts)
    run_audio_transcription_job = timeout_job_by_type('audio')(_run_audio_transcription_job)
    
    logger.info("‚úÖ All jobs imported with timeout protection")
    logger.info("üìã Main Cycle Jobs:")
    logger.info("   üì• scrape_news")
    logger.info("   üéôÔ∏è audio_transcription (STT)")
    logger.info("   üîÑ cluster_news")
    logger.info("   üìù generate_reports")
    logger.info("   üì± generate_social_media_content")
    logger.info("   üñºÔ∏è generate_images")
    logger.info("   üéµ generate_audio")
    logger.info("   üì± generate_social_media_images")
    logger.info("   üé¨ generate_reels")
    logger.info("   üì§ publish_to_social_media")
    logger.info("üìã Broadcast Cycle Jobs:")
    logger.info("   üìª generate_all_broadcasts")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Configuration
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ÿßŸÑŸÅÿ™ÿ±ÿ© ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ÿ®ŸäŸÜ ÿßŸÑÿØŸàÿ±ÿßÿ™ (ÿ®ÿßŸÑÿ´ŸàÿßŸÜŸä)
BASE_CYCLE_INTERVAL = int(os.getenv('CYCLE_INTERVAL', 120))  # 2 ÿØŸÇŸäŸÇÿ© default  

# ŸÜŸÖÿ∑ ÿßŸÑÿØŸàÿ±ÿßÿ™: ŸÜÿ¥ÿ±ÿ© ÿ£ŸàŸÑÿßŸã ÿ´ŸÖ ÿØŸàÿ±ÿ™ŸäŸÜ ÿ£ÿ≥ÿßÿ≥Ÿäÿ™ŸäŸÜ
CYCLE_PATTERN = ['broadcast', 'main', 'main']  # Broadcast ‚Üí Main ‚Üí Main ‚Üí repeat


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Job Execution
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Job Execution
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def run_job_sequential(job_name: str, job_func) -> Dict:
    """
    ÿ™ÿ¥ÿ∫ŸäŸÑ job Ÿàÿßÿ≠ÿØ ŸÖÿπ timeout protection
    """
    job_start = datetime.now()
    logger.info(f"‚ñ∂Ô∏è  Starting: {job_name}")
    
    try:
        result = job_func()
        duration = (datetime.now() - job_start).total_seconds()
        
        if result.get('skipped'):
            logger.info(f"‚è≠Ô∏è  {job_name}: Skipped ({result.get('reason', 'no reason')})")
            return {'success': True, 'skipped': True, 'duration': duration}
        elif result.get('error'):
            logger.error(f"‚ùå {job_name}: Error - {result.get('error')}")
            return {'success': False, 'error': result.get('error'), 'duration': duration}
        else:
            logger.info(f"‚úÖ {job_name}: Completed in {duration:.1f}s")
            return {'success': True, 'duration': duration}
    
    except Exception as e:
        duration = (datetime.now() - job_start).total_seconds()
        logger.error(f"‚ùå {job_name}: Exception - {e}")
        return {'success': False, 'error': str(e), 'duration': duration}


def run_main_cycle() -> Dict:
    """
    ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿØŸàÿ±ÿ© ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© (Sequential Pipeline)
    """
    logger.info(f"\n{'‚ïê'*70}")
    logger.info(f"üîÑ MAIN CYCLE - Sequential Pipeline")
    logger.info(f"{'‚ïê'*70}")
    
    cycle_start = datetime.now()
    results = {}
    
    # ÿ™ÿ≥ŸÑÿ≥ŸÑ ÿßŸÑŸÄ jobs ŸÅŸä ÿßŸÑÿØŸàÿ±ÿ© ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©
    main_jobs = [
        ('scraping', scrape_news),
        ('audio_transcription', run_audio_transcription_job),
        ('clustering', cluster_news),
        ('reports', generate_reports),
        ('social_media_content', generate_social_media_content),
        ('images', generate_images),
        ('audio', generate_audio),
        ('social_media_images', generate_social_media_images),
        ('reels', generate_reels),
        ('publishing', publish_to_social_media),
    ]
    
    # ÿ™ÿ¥ÿ∫ŸäŸÑ ŸÉŸÑ job ÿ®ÿßŸÑÿ™ÿ±ÿ™Ÿäÿ®
    for job_name, job_func in main_jobs:
        # ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑŸÄ job
        job_result = run_job_sequential(job_name, job_func)
        results[job_name] = job_result
        
        # ÿ•ÿ∞ÿß ŸÅÿ¥ŸÑ job ŸÖŸáŸÖÿå ÿ™ŸàŸÇŸÅ
        if not job_result['success'] and not job_result.get('skipped'):
            # Jobs ŸÖŸáŸÖÿ© ŸÑÿß ŸäŸÖŸÉŸÜ ÿ™ÿÆÿ∑ŸäŸáÿß
            critical_jobs = ['scraping', 'clustering', 'reports']
            if job_name in critical_jobs:
                logger.error(f"üí• Critical job {job_name} failed - stopping main cycle")
                break
        
        # ŸÅÿ™ÿ±ÿ© ÿ±ÿßÿ≠ÿ© ŸÇÿµŸäÿ±ÿ© ÿ®ŸäŸÜ ÿßŸÑŸÄ jobs (5 ÿ´ŸàÿßŸÜŸä)
        if job_name != main_jobs[-1][0]:  # ŸÖÿß ÿπÿØÿß ÿ¢ÿÆÿ± job
            logger.info(f"‚è≥ Waiting 5s before next job...")
            time.sleep(5)
    
    cycle_duration = (datetime.now() - cycle_start).total_seconds()
    
    # ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿßŸÑÿØŸàÿ±ÿ© ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ©
    successful_jobs = sum(1 for r in results.values() if r['success'])
    total_jobs = len(results)
    
    logger.info(f"\nüìä Main Cycle Summary:")
    logger.info(f"   Duration: {cycle_duration:.1f}s ({cycle_duration/60:.1f} min)")
    logger.info(f"   Success: {successful_jobs}/{total_jobs} jobs")
    
    for job_name, job_result in results.items():
        if job_result.get('skipped'):
            status = "‚è≠Ô∏è SKIPPED"
        elif job_result.get('success'):
            status = "‚úÖ SUCCESS"
        else:
            status = "‚ùå FAILED"
        
        duration = job_result.get('duration', 0)
        logger.info(f"   {status} {job_name}: {duration:.1f}s")
    
    logger.info(f"{'‚ïê'*70}")
    
    return {
        'type': 'main',
        'duration': cycle_duration,
        'results': results,
        'stats': {
            'total': total_jobs,
            'successful': successful_jobs,
            'failed': total_jobs - successful_jobs
        }
    }


def run_broadcast_cycle() -> Dict:
    """
    ÿ™ÿ¥ÿ∫ŸäŸÑ ÿØŸàÿ±ÿ© ÿßŸÑŸÜÿ¥ÿ±ÿ© (Broadcast Only)
    """
    logger.info(f"\n{'‚ïê'*70}")
    logger.info(f"üìª BROADCAST CYCLE - Newsletter & Digest")
    logger.info(f"{'‚ïê'*70}")
    
    cycle_start = datetime.now()
    results = {}
    
    # ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑŸÜÿ¥ÿ±ÿ© ŸàÿßŸÑŸÖŸàÿ¨ÿ≤
    broadcast_result = run_job_sequential('broadcast', generate_all_broadcasts)
    results['broadcast'] = broadcast_result
    
    cycle_duration = (datetime.now() - cycle_start).total_seconds()
    
    # ÿ•ÿ≠ÿµÿßÿ¶Ÿäÿßÿ™ ÿØŸàÿ±ÿ© ÿßŸÑŸÜÿ¥ÿ±ÿ©
    logger.info(f"\nüìä Broadcast Cycle Summary:")
    logger.info(f"   Duration: {cycle_duration:.1f}s ({cycle_duration/60:.1f} min)")
    
    if broadcast_result.get('skipped'):
        status = "‚è≠Ô∏è SKIPPED"
    elif broadcast_result.get('success'):
        status = "‚úÖ SUCCESS"
    else:
        status = "‚ùå FAILED"
    
    duration = broadcast_result.get('duration', 0)
    logger.info(f"   {status} broadcast: {duration:.1f}s")
    logger.info(f"{'‚ïê'*70}")
    
    return {
        'type': 'broadcast',
        'duration': cycle_duration,
        'results': results,
        'stats': {
            'total': 1,
            'successful': 1 if broadcast_result['success'] else 0,
            'failed': 0 if broadcast_result['success'] else 1
        }
    }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Main Cycle
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Main Cycle Logic
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def run_cycle(cycle_number: int) -> Dict:
    """
    ÿ™ÿ¥ÿ∫ŸäŸÑ ÿØŸàÿ±ÿ© ÿ≠ÿ≥ÿ® ÿßŸÑŸÜŸÖÿ∑ ÿßŸÑŸÖÿ≠ÿØÿØ
    """
    cycle_start = datetime.now()
    
    # ÿ™ÿ≠ÿØŸäÿØ ŸÜŸàÿπ ÿßŸÑÿØŸàÿ±ÿ© ÿ≠ÿ≥ÿ® ÿßŸÑŸÜŸÖÿ∑
    pattern_index = (cycle_number - 1) % len(CYCLE_PATTERN)
    cycle_type = CYCLE_PATTERN[pattern_index]
    
    logger.info("\n" + "‚ïê"*70)
    logger.info(f"üîÑ CYCLE #{cycle_number} ({cycle_type.upper()}) started at {cycle_start.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"Pattern: {' ‚Üí '.join(CYCLE_PATTERN)} (position {pattern_index + 1})")
    logger.info("‚ïê"*70)
    
    # ÿ™ÿ¥ÿ∫ŸäŸÑ ÿßŸÑÿØŸàÿ±ÿ© ÿßŸÑŸÖŸÜÿßÿ≥ÿ®ÿ©
    if cycle_type == 'main':
        result = run_main_cycle()
    elif cycle_type == 'broadcast':
        result = run_broadcast_cycle()
    else:
        logger.error(f"‚ùå Unknown cycle type: {cycle_type}")
        return {
            'cycle': cycle_number,
            'type': cycle_type,
            'duration': 0,
            'error': f'Unknown cycle type: {cycle_type}'
        }
    
    # ÿ•ÿ∂ÿßŸÅÿ© ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿØŸàÿ±ÿ©
    result['cycle'] = cycle_number
    result['cycle_type'] = cycle_type
    result['pattern_position'] = pattern_index + 1
    
    total_duration = (datetime.now() - cycle_start).total_seconds()
    
    logger.info("\n" + "‚ïê"*70)
    logger.info(f"üìä CYCLE #{cycle_number} ({cycle_type.upper()}) Summary")
    logger.info("‚ïê"*70)
    logger.info(f"Total Duration: {total_duration:.1f}s ({total_duration/60:.1f} min)")
    logger.info(f"Pattern Position: {pattern_index + 1}/{len(CYCLE_PATTERN)} ({cycle_type})")
    
    stats = result.get('stats', {})
    successful = stats.get('successful', 0)
    total = stats.get('total', 0)
    failed = stats.get('failed', 0)
    
    logger.info(f"Jobs: {successful}‚úÖ {failed}‚ùå / {total} total")
    
    # ÿπÿ±ÿ∂ ÿßŸÑŸÄ job ÿßŸÑÿ™ÿßŸÑŸä
    next_pattern_index = cycle_number % len(CYCLE_PATTERN)
    next_cycle_type = CYCLE_PATTERN[next_pattern_index]
    logger.info(f"Next Cycle: #{cycle_number + 1} ({next_cycle_type.upper()})")
    logger.info("‚ïê"*70 + "\n")
    
    return result


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Manual Job Execution (for API)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def run_job_now(task_type: str) -> bool:
    """
    ÿ™ÿ¥ÿ∫ŸäŸÑ job ŸäÿØŸàŸäÿßŸã ŸÖŸÜ ÿßŸÑŸÄ API
    
    Args:
        task_type: ŸÜŸàÿπ ÿßŸÑŸÄ task (ŸÖÿ´ŸÑ: audio_transcription, clustering, etc.)
    
    Returns:
        bool: ŸÜÿ¨ÿ≠ ÿ£Ÿà ŸÑÿß
    """
    try:
        # Import the specific job
        if task_type == 'audio_transcription':
            from app.jobs.audio_transcription_job import run_audio_transcription_job
            result = run_audio_transcription_job()
            return result.get('success', 0) > 0 or result.get('processed', 0) == 0
            
        elif task_type == 'scraping':
            from app.jobs.scraper_job import scrape_news
            result = scrape_news()
            return not result.get('error')
            
        elif task_type == 'clustering':
            from app.jobs.clustering_job import cluster_news
            result = cluster_news()
            return not result.get('error')
            
        elif task_type == 'report_generation':
            from app.jobs.reports_job import generate_reports
            result = generate_reports()
            return not result.get('error')
            
        elif task_type == 'social_media_generation':
            from app.jobs.social_media_job import generate_social_media_content
            result = generate_social_media_content()
            return not result.get('error')
            
        elif task_type == 'image_generation':
            from app.jobs.image_generation_job import generate_images
            result = generate_images()
            return not result.get('error')
            
        elif task_type == 'audio_generation':
            from app.jobs.audio_generation_job import generate_audio
            result = generate_audio()
            return not result.get('error')
            
        elif task_type == 'bulletin_generation' or task_type == 'digest_generation':
            from app.jobs.broadcast_job import generate_all_broadcasts
            result = generate_all_broadcasts()
            return not result.get('error')
            
        else:
            logger.error(f"Unknown task type: {task_type}")
            return False
            
    except Exception as e:
        logger.error(f"Error running job {task_type}: {e}")
        traceback.print_exc()
        return False


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Main Loop
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Global flag for graceful shutdown
running = True


def signal_handler(signum, frame):
    """Handle shutdown signals"""
    global running
    logger.info("\n‚ö†Ô∏è  Shutdown signal received, finishing current cycle...")
    running = False


def main():
    """Main entry point"""
    global running
    
    logger.info("‚ïê"*70)
    logger.info("üöÄ Sequential Pipeline Scheduler Starting")
    logger.info("   ‚úÖ Sequential job execution")
    logger.info("   ‚úÖ Individual job timeouts")
    logger.info("   ‚úÖ Cycle pattern system")
    logger.info("   ‚úÖ Error isolation")
    logger.info("‚ïê"*70)
    logger.info(f"Environment: {os.getenv('ENVIRONMENT', 'development')}")
    
    # Check FFmpeg availability
    try:
        from app.utils.audio_converter import AudioConverter
        audio_converter = AudioConverter()
        
        if audio_converter.is_ffmpeg_available():
            logger.info("‚úÖ FFmpeg available")
        else:
            logger.warning("‚ö†Ô∏è  FFmpeg not available - audio features may be limited")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è  Could not check FFmpeg availability: {e}")
    
    logger.info(f"Base cycle interval: {BASE_CYCLE_INTERVAL}s ({BASE_CYCLE_INTERVAL//60} min)")
    logger.info("")
    logger.info("Cycle Pattern:")
    for i, cycle_type in enumerate(CYCLE_PATTERN, 1):
        logger.info(f"  {i}. {cycle_type.upper()} Cycle")
    logger.info(f"  Pattern repeats every {len(CYCLE_PATTERN)} cycles")
    logger.info("")
    logger.info("Main Cycle Jobs (Sequential):")
    logger.info("  1. üì• Scraping")
    logger.info("  2. üéôÔ∏è Audio Transcription (STT)")
    logger.info("  3. üîÑ Clustering") 
    logger.info("  4. üìù Reports Generation")
    logger.info("  5. üì± Social Media Content")
    logger.info("  6. üñºÔ∏è Image Generation")
    logger.info("  7. üéµ Audio Generation")
    logger.info("  8. üì± Social Media Images")
    logger.info("  9. üé¨ Reel Generation")
    logger.info("  10. üì§ Publishing")
    logger.info("")
    logger.info("Broadcast Cycle Jobs:")
    logger.info("  1. üìª Newsletter & Digest Generation")
    logger.info("‚ïê"*70)
    
    # Setup signal handlers
    signal.signal(signal.SIGTERM, signal_handler)
    signal.signal(signal.SIGINT, signal_handler)
    
    # Import jobs
    try:
        import_jobs()
    except Exception as e:
        logger.error(f"‚ùå Failed to import jobs: {e}")
        traceback.print_exc()
        sys.exit(1)
    
    cycle_number = 0
    
    while running:
        cycle_number += 1
        
        try:
            # Run the cycle
            cycle_result = run_cycle(cycle_number)
            
            # Log performance metrics
            if 'error' in cycle_result:
                logger.error(f"‚ùå Cycle #{cycle_number} failed: {cycle_result['error']}")
            else:
                stats = cycle_result.get('stats', {})
                cycle_type = cycle_result.get('cycle_type', 'unknown')
                
                if stats.get('failed', 0) > 0:
                    logger.warning(f"‚ö†Ô∏è  {stats['failed']} jobs failed in {cycle_type} cycle #{cycle_number}")
                else:
                    logger.info(f"‚úÖ {cycle_type.title()} cycle #{cycle_number} completed successfully")
            
            if not running:
                break
            
            # Wait for next cycle
            logger.info(f"üí§ Waiting {BASE_CYCLE_INTERVAL}s ({BASE_CYCLE_INTERVAL//60} min) until next cycle...")
            
            # Sleep in small increments to allow for graceful shutdown
            for _ in range(BASE_CYCLE_INTERVAL):
                if not running:
                    break
                time.sleep(1)
                
        except KeyboardInterrupt:
            logger.info("\n‚ö†Ô∏è  Keyboard interrupt received")
            break
            
        except Exception as e:
            logger.error(f"‚ùå Cycle error: {e}")
            traceback.print_exc()
            
            # Wait a bit before retrying
            logger.info("‚è≥ Waiting 60s before retry...")
            for _ in range(60):
                if not running:
                    break
                time.sleep(1)
    
    logger.info("\n" + "‚ïê"*70)
    logger.info("üõë Sequential Pipeline Scheduler stopped gracefully")
    logger.info("‚ïê"*70)


if __name__ == "__main__":
    main()